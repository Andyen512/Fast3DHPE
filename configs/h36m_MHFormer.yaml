# ========= Dataset =========
DATASET:
  train_dataset: "H36M"                   # Dataset name, affects load path
  root: "data"                   # Directory containing data_3d_h36m.npz / data_2d_h36m_xxx.npz
  keypoints: "cpn_ft_h36m_dbb"   # Name of the 2D keypoint detector you use
  subjects_train: "S1,S5,S6,S7,S8"   # Training subjects
  subjects_unlabeled:  ""           # Test subjects
  subjects_test: "S9,S11"             # For semi-supervised use (optional)
  downsample: 1                  # Global downsampling factor
  subset: 1.0                    # Subset ratio (use <1.0 for small-sample experiments)
  receptive_field: 27
  chunk_size: 1
  batch_size: 1024
  stride: 1
  Root_idx: 0
  Cross_Dataset: False
  test_dataset: H36M
  dataset_type: 'seq2seq'
  frame_stride: 1


  Test:
    actions: '*'   
    P2: True 
    Eval_type: 'Normal' 

# ========= Model =========
MODEL:
  name: "MHFormer"
  backbone:
    num_frame: 27 
    num_block: 3
    num_joints: 17
    embed_dim_ratio: 512
    d_hid: 1024

    
    

# ========= Loss =========
LOSS:
  type: "MPJPELoss"
  log_prefix: "mpjpe"
  loss_term_weight: 1.0



# ========= Optimizer & Learning Rate =========
OPTIM:
  name: "AdamW"
  lr: 0.00012
  weight_decay: 0.001
  lr_decay: 0.950

SCHED:
  name: "Cosine"
  warmup_epochs: 5
  max_epochs: 400

# ========= Training Engine =========
ENGINE:
  save_name: "h36m_MHFormer_lr0012_lrd950_amp"    # Part of the save path
  amp: true                    # Automatic mixed precision
  find_unused_parameters: False
  log_interval: 50
  val_interval: 1
  save_freq: 200

# ========= Runtime Settings =========
RUNTIME:
  seed: 1

DEBUG: False
EVAL: True